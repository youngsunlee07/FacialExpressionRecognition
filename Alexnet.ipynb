{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6aafbfa-2d87-4f34-91fc-6228d87954b9",
   "metadata": {},
   "source": [
    "# AlexNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cfbd0c8-48c1-4773-ad47-f0bf80f9b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.init as init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea894a5b-fb50-4dab-b737-83efa4a0c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FERDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "        self.data = []\n",
    "\n",
    "        for label, emotion in enumerate(self.classes):\n",
    "            emotion_dir = os.path.join(root_dir, emotion)\n",
    "            for filename in os.listdir(emotion_dir):\n",
    "                img_path = os.path.join(emotion_dir, filename)\n",
    "                if os.path.exists(img_path):  \n",
    "                    self.data.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "\n",
    "        for _ in range(3):  \n",
    "            try:\n",
    "                image = Image.open(img_path).convert('L')  \n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return image, label\n",
    "            except FileNotFoundError:\n",
    "                time.sleep(1) \n",
    "        raise FileNotFoundError(f\"Failed to open {img_path} after multiple attempts.\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  \n",
    "    transforms.Resize((230, 230)),  \n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.RandomCrop(224, padding=8),  \n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = FERDataset('C:/Users/user/Desktop/DLProject/FER-2013/train', transform=transform)\n",
    "test_dataset = FERDataset('C:/Users/user/Desktop/DLProject/FER-2013/test', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78995c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.alexnet(num_classes=7)\n",
    "# Modify the first convolution layer to accept 1-channel (grayscale) images\n",
    "model.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "# Update the final classifier layer to match the number of classes\n",
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=7)\n",
    "model = model.to(device) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 30], gamma=0.1)\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print training accuracy and loss after each epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_loss/len(train_loader):.4f}, Training Accuracy: {100.*correct/total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Appending labels and predictions for further evaluation\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_outputs.extend(outputs.cpu().numpy())\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "num_classes = 7\n",
    "all_labels_bin = label_binarize(all_labels, classes=[i for i in range(num_classes)])\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(all_labels_bin[:, i], np.array(all_outputs)[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "for i in range(num_classes):\n",
    "    print(f\"Class {i} AUC: {roc_auc[i]}\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (area = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
